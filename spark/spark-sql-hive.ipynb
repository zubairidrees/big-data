{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+-----------+-----------+\n",
      "|  tableName|isTemporary|\n",
      "+-----------+-----------+\n",
      "|  customers|      false|\n",
      "|order_items|      false|\n",
      "|     orders|      false|\n",
      "+-----------+-----------+\n",
      "\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------+\n",
      "|   order_status|CASE WHEN (order_status = COMPLETE) THEN No Action WHEN (order_status = CLOSED) THEN No Action ELSE Risky END|\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------+\n",
      "|         CLOSED|                                                                                                    No Action|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|         CLOSED|                                                                                                    No Action|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|     PROCESSING|                                                                                                        Risky|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "| PAYMENT_REVIEW|                                                                                                        Risky|\n",
      "|         CLOSED|                                                                                                    No Action|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "|     PROCESSING|                                                                                                        Risky|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "|       COMPLETE|                                                                                                    No Action|\n",
      "|         CLOSED|                                                                                                    No Action|\n",
      "|PENDING_PAYMENT|                                                                                                        Risky|\n",
      "|     PROCESSING|                                                                                                        Risky|\n",
      "+---------------+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+-------------------+\n",
      "|   order_status|count(order_status)|\n",
      "+---------------+-------------------+\n",
      "|PENDING_PAYMENT|              15030|\n",
      "|       COMPLETE|              22899|\n",
      "|        ON_HOLD|               3798|\n",
      "| PAYMENT_REVIEW|                729|\n",
      "|     PROCESSING|               8275|\n",
      "|         CLOSED|               7556|\n",
      "|SUSPECTED_FRAUD|               1558|\n",
      "|        PENDING|               7610|\n",
      "|       CANCELED|               1428|\n",
      "+---------------+-------------------+\n",
      "\n",
      "Row(order_id=42, order_status=u'PENDING', sum(order_item_subtotal)=739.9200248718262)\n",
      "+---+-----+\n",
      "|  1|Hello|\n",
      "+---+-----+\n",
      "|  1|Hello|\n",
      "|  2|world|\n",
      "|  3|Hello|\n",
      "+---+-----+\n",
      "\n",
      "Row(order_id=41098, order_date=u'2014-04-03 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=23322, order_date=u'2013-12-16 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=21816, order_date=u'2013-12-06 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=12380, order_date=u'2013-10-08 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=11102, order_date=u'2013-10-01 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=5557, order_date=u'2013-08-27 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=1944, order_date=u'2013-08-04 00:00:00.0', order_item_subtotal=9.989999771118164, revenue=9.99, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=36546, order_date=u'2014-03-06 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=26612, order_date=u'2014-01-05 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=26149, order_date=u'2014-01-03 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=21543, order_date=u'2013-12-05 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=18772, order_date=u'2013-11-18 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=7530, order_date=u'2013-09-09 00:00:00.0', order_item_subtotal=14.989999771118164, revenue=14.99, percentage_revenue=0.9999999847310316)\n",
      "Row(order_id=44889, order_date=u'2014-04-29 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=43362, order_date=u'2014-04-20 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=42909, order_date=u'2014-04-16 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=36363, order_date=u'2014-03-05 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=26564, order_date=u'2014-01-05 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=24110, order_date=u'2013-12-21 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=17796, order_date=u'2013-11-12 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=3660, order_date=u'2013-08-15 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=2031, order_date=u'2013-08-05 00:00:00.0', order_item_subtotal=15.989999771118164, revenue=15.99, percentage_revenue=0.999999985685939)\n",
      "Row(order_id=57048, order_date=u'2014-07-20 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=57064, order_date=u'2014-07-20 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=48974, order_date=u'2014-05-25 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=45908, order_date=u'2014-05-06 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=42332, order_date=u'2014-04-12 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=9670, order_date=u'2013-09-24 00:00:00.0', order_item_subtotal=17.989999771118164, revenue=17.99, percentage_revenue=0.9999999872772743)\n",
      "Row(order_id=29479, order_date=u'2014-01-23 00:00:00.0', order_item_subtotal=19.979999542236328, revenue=19.98, percentage_revenue=0.9999999770889053)\n",
      "Row(order_id=57688, order_date=u'2014-07-24 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=45696, order_date=u'2014-05-04 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=44853, order_date=u'2014-04-29 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=34833, order_date=u'2014-02-25 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=32657, order_date=u'2014-02-11 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=31446, order_date=u'2014-02-04 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=27491, order_date=u'2014-01-11 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=23994, order_date=u'2013-12-21 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=23142, order_date=u'2013-12-15 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=18558, order_date=u'2013-11-17 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=15731, order_date=u'2013-11-02 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=15736, order_date=u'2013-11-02 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=9786, order_date=u'2013-09-24 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=7711, order_date=u'2013-09-10 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=5082, order_date=u'2013-08-24 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=2098, order_date=u'2013-08-05 00:00:00.0', order_item_subtotal=19.989999771118164, revenue=19.99, percentage_revenue=0.9999999885501833)\n",
      "Row(order_id=48176, order_date=u'2014-05-20 00:00:00.0', order_item_subtotal=22.0, revenue=22.0, percentage_revenue=1.0)\n",
      "Row(order_id=29784, order_date=u'2014-01-25 00:00:00.0', order_item_subtotal=22.0, revenue=22.0, percentage_revenue=1.0)\n",
      "Row(order_id=21125, order_date=u'2013-12-02 00:00:00.0', order_item_subtotal=22.0, revenue=22.0, percentage_revenue=1.0)\n",
      "Row(order_id=56510, order_date=u'2014-07-17 00:00:00.0', order_item_subtotal=24.989999771118164, revenue=24.99, percentage_revenue=0.9999999908410631)\n",
      "Row(order_id=50265, order_date=u'2014-06-05 00:00:00.0', order_item_subtotal=24.989999771118164, revenue=24.99, percentage_revenue=0.9999999908410631)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sqlContext.sql(\"use retail_db_txt\").show()\n",
    "sqlContext.sql(\"show tables\").show()\n",
    "sqlContext.sql(\"select distinct order_status from orders limit 10\")\n",
    "sqlContext.sql(\"select order_status , case order_status when 'COMPLETE' then 'No Action' \\\n",
    "                                         when 'CLOSED' then 'No Action' \\\n",
    "                                          else 'Risky' end \\\n",
    "                                         from orders\")\n",
    "\n",
    "sqlContext.sql(\"select order_status , case when order_status IN ('COMPLETE', 'CLOSED') then 'No Action' \\\n",
    "                                           when order_status IN ('PENDING_PAYMENT') then 'Pending' \\\n",
    "                                           else 'Risky' end \\\n",
    "                                         from orders\")\n",
    "sqlContext.sql(\"select nvl(order_status,'Status Missing') from orders limit 100\")\n",
    "\n",
    "sqlContext.sql(\"select cast(concat(substr(order_date,1,4),substr(order_date,6,2)) as int) from orders\")\n",
    "\n",
    "sqlContext.sql(\"select date_format(order_date,'YYYYMM') from orders\")\n",
    "\n",
    "sqlContext.sql(\"select o.*,oi.order_item_product_id from orders o inner join order_items oi on o.order_id = order_item_order_id\")\n",
    "\n",
    "sqlContext.sql(\"select order_status,count(order_status) from orders group by order_status\"))\n",
    "\n",
    "d = sqlContext.sql(\"select order_id,order_status, sum(order_item_subtotal) from orders o inner join order_items oi on o.order_id = oi.order_item_order_id group by order_id,order_status\")\n",
    "\n",
    "for i in d.collect():\n",
    "    if(i.order_id == 42):\n",
    "        print i\n",
    "sqlContext.sql(\"select order_id,order_date, sum(order_item_subtotal) as revenue from orders o inner join order_items oi on o.order_id = oi.order_item_order_id group by order_id,order_date having sum(order_item_subtotal) >= 1000 order by revenue,order_date desc\")\n",
    "\n",
    "sqlContext.sql(\"select order_id,order_date, sum(order_item_subtotal) as revenue from orders o inner join order_items oi on o.order_id = oi.order_item_order_id group by order_id,order_date having sum(order_item_subtotal) >= 1000 distribute by o.order_date sort by order_date,revenue desc\")\n",
    "\n",
    "#union all for all records\n",
    "sqlContext.sql(\"select 1, 'Hello' union all select 2, 'world' union all select 3, 'Hello'\")\n",
    "\n",
    "#union for disctinct\n",
    "#sqlContext.sql(\"select 1, 'Hello' union select 2, 'world' union select 3, 'Hello'\")\n",
    "\n",
    "l = sqlContext.sql(\"select order_id,order_date,order_item_subtotal, round(sum(order_item_subtotal) over (partition by order_id),2) as revenue, order_item_subtotal/round(sum(order_item_subtotal) over (partition by order_id),2) as percentage_revenue from orders o inner join order_items oi on o.order_id = oi.order_item_order_id order by revenue,order_date desc\")\n",
    "for i in l.take(50):print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sqlContext.sql(\"select 1, 'Hello' union all select 2, 'world' union all select 3, 'Hello'\").show()\n",
    "print \"sdas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|  tableName|isTemporary|\n",
      "+-----------+-----------+\n",
      "|  customers|      false|\n",
      "|order_items|      false|\n",
      "|     orders|      false|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"use retail_db_txt\")\n",
    "sqlContext.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sqlContext.sql(\"select order_id,order_date,order_item_subtotal, round(sum(order_item_subtotal) over (partition by order_id),2) as revenue, order_item_subtotal/round(sum(order_item_subtotal) over (partition by order_id),2) as percentage_revenue from orders o inner join order_items oi on o.order_id = oi.order_item_order_id \\\n",
    "order by revenue,order_date desc\")\n",
    "for i in l.take(2):\n",
    "    if i.order_id == 8210:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank() , dense_rank , percentage_rank, row_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=399.9800109863281, order_revenue=1004.92, percentage_revenue=0.3980217440058195, r_revenue=1, d_revenue=1, p_revenue=0.0, rn_revenue=1)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=399.9800109863281, order_revenue=1004.92, percentage_revenue=0.3980217440058195, r_revenue=1, d_revenue=1, p_revenue=0.0, rn_revenue=2)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=129.99000549316406, order_revenue=1004.92, percentage_revenue=0.12935358585077825, r_revenue=3, d_revenue=2, p_revenue=0.6666666666666666, rn_revenue=3)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=74.97000122070312, order_revenue=1004.92, percentage_revenue=0.07460295468365952, r_revenue=4, d_revenue=3, p_revenue=1.0, rn_revenue=4)\n"
     ]
    }
   ],
   "source": [
    "l = sqlContext.sql(\"select * from (\\\n",
    "                     select order_id,order_date,order_item_subtotal, \\\n",
    "                     round(sum(order_item_subtotal) over (partition by order_id),2) as order_revenue, \\\n",
    "                     order_item_subtotal/round(sum(order_item_subtotal) over (partition by order_id),2) \\\n",
    "                     as percentage_revenue, \\\n",
    "                     rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) r_revenue, \\\n",
    "                     dense_rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) d_revenue, \\\n",
    "                     percent_rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) p_revenue, \\\n",
    "                     row_number() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) rn_revenue \\\n",
    "                     from orders o inner join order_items oi on o.order_id = oi.order_item_order_id \\\n",
    "                     where o.order_status in ('COMPLETE', 'CLOSED')) q where q.order_revenue >= 1000 \\\n",
    "                     order by q.order_revenue,q.order_date desc, q.rn_revenue \")\n",
    "for i in l.take(50):\n",
    "    if i.order_id == 8210:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lead lag, first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=399.9800109863281, order_revenue=1004.92, percentage_revenue=0.3980217440058195, r_revenue=1, d_revenue=1, p_revenue=0.0, rn_revenue=1, lead_subtotlast_subtotal=399.9800109863281, lag_subtotal=None, first_subtotal=399.9800109863281, last_subtotal=399.9800109863281)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=399.9800109863281, order_revenue=1004.92, percentage_revenue=0.3980217440058195, r_revenue=1, d_revenue=1, p_revenue=0.0, rn_revenue=2, lead_subtotlast_subtotal=129.99000549316406, lag_subtotal=399.9800109863281, first_subtotal=399.9800109863281, last_subtotal=399.9800109863281)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=129.99000549316406, order_revenue=1004.92, percentage_revenue=0.12935358585077825, r_revenue=3, d_revenue=2, p_revenue=0.6666666666666666, rn_revenue=3, lead_subtotlast_subtotal=74.97000122070312, lag_subtotal=399.9800109863281, first_subtotal=399.9800109863281, last_subtotal=129.99000549316406)\n",
      "Row(order_id=8210, order_date=u'2013-09-14 00:00:00.0', order_item_subtotal=74.97000122070312, order_revenue=1004.92, percentage_revenue=0.07460295468365952, r_revenue=4, d_revenue=3, p_revenue=1.0, rn_revenue=4, lead_subtotlast_subtotal=None, lag_subtotal=129.99000549316406, first_subtotal=399.9800109863281, last_subtotal=74.97000122070312)\n"
     ]
    }
   ],
   "source": [
    "l = sqlContext.sql(\"select * from (\\\n",
    "                     select order_id,order_date,order_item_subtotal, \\\n",
    "                     round(sum(order_item_subtotal) over (partition by order_id),2) as order_revenue, \\\n",
    "                     order_item_subtotal/round(sum(order_item_subtotal) over (partition by order_id),2) \\\n",
    "                     as percentage_revenue, \\\n",
    "                     rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) r_revenue, \\\n",
    "                     dense_rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) d_revenue, \\\n",
    "                     percent_rank() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) p_revenue, \\\n",
    "                     row_number() over(partition by oi.order_item_order_id order by oi.order_item_subtotal desc) rn_revenue, \\\n",
    "                     lead(oi.order_item_subtotal) over (partition by o.order_id order by oi.order_item_subtotal desc) lead_subtotlast_subtotal, \\\n",
    "                     lag(oi.order_item_subtotal) over (partition by o.order_id order by oi.order_item_subtotal desc) lag_subtotal, \\\n",
    "                     first_value(oi.order_item_subtotal) over (partition by o.order_id order by oi.order_item_subtotal desc) first_subtotal, \\\n",
    "                     last_value(oi.order_item_subtotal) over (partition by o.order_id order by oi.order_item_subtotal desc) last_subtotal \\\n",
    "                     from orders o inner join order_items oi on o.order_id = oi.order_item_order_id \\\n",
    "                     where o.order_status in ('COMPLETE', 'CLOSED')) q where q.order_revenue >= 1000 \\\n",
    "                     order by q.order_revenue,q.order_date desc, q.rn_revenue \")\n",
    "for i in l.take(50):\n",
    "    if i.order_id == 8210:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "u\"\\nextraneous input '*' expecting {<EOF>, ',', 'SELECT', 'FROM', 'ADD', 'AS', 'ALL', 'DISTINCT', 'WHERE', 'GROUP', 'BY', 'GROUPING', 'SETS', 'CUBE', 'ROLLUP', 'ORDER', 'HAVING', 'LIMIT', 'AT', 'OR', 'AND', 'IN', NOT, 'NO', 'EXISTS', 'BETWEEN', 'LIKE', RLIKE, 'IS', 'NULL', 'TRUE', 'FALSE', 'NULLS', 'ASC', 'DESC', 'FOR', 'INTERVAL', 'CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'JOIN', 'CROSS', 'OUTER', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'NATURAL', 'LATERAL', 'WINDOW', 'OVER', 'PARTITION', 'RANGE', 'ROWS', 'UNBOUNDED', 'PRECEDING', 'FOLLOWING', 'CURRENT', 'ROW', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'VIEW', 'REPLACE', 'INSERT', 'DELETE', 'INTO', 'DESCRIBE', 'EXPLAIN', 'FORMAT', 'LOGICAL', 'CODEGEN', 'CAST', 'SHOW', 'TABLES', 'COLUMNS', 'COLUMN', 'USE', 'PARTITIONS', 'FUNCTIONS', 'DROP', 'UNION', 'EXCEPT', 'INTERSECT', 'TO', 'TABLESAMPLE', 'STRATIFY', 'ALTER', 'RENAME', 'ARRAY', 'MAP', 'STRUCT', 'COMMENT', 'SET', 'RESET', 'DATA', 'START', 'TRANSACTION', 'COMMIT', 'ROLLBACK', 'MACRO', 'IF', 'DIV', 'PERCENT', 'BUCKET', 'OUT', 'OF', 'SORT', 'CLUSTER', 'DISTRIBUTE', 'OVERWRITE', 'TRANSFORM', 'REDUCE', 'USING', 'SERDE', 'SERDEPROPERTIES', 'RECORDREADER', 'RECORDWRITER', 'DELIMITED', 'FIELDS', 'TERMINATED', 'COLLECTION', 'ITEMS', 'KEYS', 'ESCAPED', 'LINES', 'SEPARATED', 'FUNCTION', 'EXTENDED', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'LAZY', 'FORMATTED', TEMPORARY, 'OPTIONS', 'UNSET', 'TBLPROPERTIES', 'DBPROPERTIES', 'BUCKETS', 'SKEWED', 'STORED', 'DIRECTORIES', 'LOCATION', 'EXCHANGE', 'ARCHIVE', 'UNARCHIVE', 'FILEFORMAT', 'TOUCH', 'COMPACT', 'CONCATENATE', 'CHANGE', 'CASCADE', 'RESTRICT', 'CLUSTERED', 'SORTED', 'PURGE', 'INPUTFORMAT', 'OUTPUTFORMAT', DATABASE, DATABASES, 'DFS', 'TRUNCATE', 'ANALYZE', 'COMPUTE', 'LIST', 'STATISTICS', 'PARTITIONED', 'EXTERNAL', 'DEFINED', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'REPAIR', 'RECOVER', 'EXPORT', 'IMPORT', 'LOAD', 'ROLE', 'ROLES', 'COMPACTIONS', 'PRINCIPALS', 'TRANSACTIONS', 'INDEX', 'INDEXES', 'LOCKS', 'OPTION', 'ANTI', 'LOCAL', 'INPATH', 'CURRENT_DATE', 'CURRENT_TIMESTAMP', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 45)\\n\\n== SQL ==\\ninsert into retail_db_orc.orders from select * from retail_db_txt.orders\\n---------------------------------------------^^^\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2649afd49059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sqlContext.sql(\"load data local inpath '/home/zubairidrees/hadoop-2.7.3/data/retail_db/orders' into table orders\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#sqlContext.sql(\"create table order_items (order_item_id int, order_item_order_id int, order_item_product_id int, order_item_quantity int,order_item_subtotal float, order_item_product_price float) stored as orc\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"insert into retail_db_orc.orders from select * from retail_db_txt.orders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"insert into retail_db_orc.order_items from select * from retail_db_txt.order_items\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/context.pyc\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/session.pyc\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.parser.ParseException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.streaming.StreamingQueryException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStreamingQueryException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParseException\u001b[0m: u\"\\nextraneous input '*' expecting {<EOF>, ',', 'SELECT', 'FROM', 'ADD', 'AS', 'ALL', 'DISTINCT', 'WHERE', 'GROUP', 'BY', 'GROUPING', 'SETS', 'CUBE', 'ROLLUP', 'ORDER', 'HAVING', 'LIMIT', 'AT', 'OR', 'AND', 'IN', NOT, 'NO', 'EXISTS', 'BETWEEN', 'LIKE', RLIKE, 'IS', 'NULL', 'TRUE', 'FALSE', 'NULLS', 'ASC', 'DESC', 'FOR', 'INTERVAL', 'CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'JOIN', 'CROSS', 'OUTER', 'INNER', 'LEFT', 'RIGHT', 'FULL', 'NATURAL', 'LATERAL', 'WINDOW', 'OVER', 'PARTITION', 'RANGE', 'ROWS', 'UNBOUNDED', 'PRECEDING', 'FOLLOWING', 'CURRENT', 'ROW', 'WITH', 'VALUES', 'CREATE', 'TABLE', 'VIEW', 'REPLACE', 'INSERT', 'DELETE', 'INTO', 'DESCRIBE', 'EXPLAIN', 'FORMAT', 'LOGICAL', 'CODEGEN', 'CAST', 'SHOW', 'TABLES', 'COLUMNS', 'COLUMN', 'USE', 'PARTITIONS', 'FUNCTIONS', 'DROP', 'UNION', 'EXCEPT', 'INTERSECT', 'TO', 'TABLESAMPLE', 'STRATIFY', 'ALTER', 'RENAME', 'ARRAY', 'MAP', 'STRUCT', 'COMMENT', 'SET', 'RESET', 'DATA', 'START', 'TRANSACTION', 'COMMIT', 'ROLLBACK', 'MACRO', 'IF', 'DIV', 'PERCENT', 'BUCKET', 'OUT', 'OF', 'SORT', 'CLUSTER', 'DISTRIBUTE', 'OVERWRITE', 'TRANSFORM', 'REDUCE', 'USING', 'SERDE', 'SERDEPROPERTIES', 'RECORDREADER', 'RECORDWRITER', 'DELIMITED', 'FIELDS', 'TERMINATED', 'COLLECTION', 'ITEMS', 'KEYS', 'ESCAPED', 'LINES', 'SEPARATED', 'FUNCTION', 'EXTENDED', 'REFRESH', 'CLEAR', 'CACHE', 'UNCACHE', 'LAZY', 'FORMATTED', TEMPORARY, 'OPTIONS', 'UNSET', 'TBLPROPERTIES', 'DBPROPERTIES', 'BUCKETS', 'SKEWED', 'STORED', 'DIRECTORIES', 'LOCATION', 'EXCHANGE', 'ARCHIVE', 'UNARCHIVE', 'FILEFORMAT', 'TOUCH', 'COMPACT', 'CONCATENATE', 'CHANGE', 'CASCADE', 'RESTRICT', 'CLUSTERED', 'SORTED', 'PURGE', 'INPUTFORMAT', 'OUTPUTFORMAT', DATABASE, DATABASES, 'DFS', 'TRUNCATE', 'ANALYZE', 'COMPUTE', 'LIST', 'STATISTICS', 'PARTITIONED', 'EXTERNAL', 'DEFINED', 'REVOKE', 'GRANT', 'LOCK', 'UNLOCK', 'MSCK', 'REPAIR', 'RECOVER', 'EXPORT', 'IMPORT', 'LOAD', 'ROLE', 'ROLES', 'COMPACTIONS', 'PRINCIPALS', 'TRANSACTIONS', 'INDEX', 'INDEXES', 'LOCKS', 'OPTION', 'ANTI', 'LOCAL', 'INPATH', 'CURRENT_DATE', 'CURRENT_TIMESTAMP', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 45)\\n\\n== SQL ==\\ninsert into retail_db_orc.orders from select * from retail_db_txt.orders\\n---------------------------------------------^^^\\n\""
     ]
    }
   ],
   "source": [
    "#sqlContext.sql(\"create database retail_db_orc\")\n",
    "sqlContext.sql(\"use retail_db_orc\")\n",
    "#sqlContext.sql(\"create table orders (order_id int, order_date string, order_customer_id int,order_status string ) stored as orc\")\n",
    "#sqlContext.sql(\"load data local inpath '/home/zubairidrees/hadoop-2.7.3/data/retail_db/orders' into table orders\")\n",
    "#sqlContext.sql(\"create table order_items (order_item_id int, order_item_order_id int, order_item_product_id int, order_item_quantity int,order_item_subtotal float, order_item_product_price float) stored as orc\")\n",
    "sqlContext.sql(\"insert into retail_db_orc.orders from select * from retail_db_txt.orders\")\n",
    "sqlContext.sql(\"insert into retail_db_orc.order_items from select * from retail_db_txt.order_items\")\n",
    "\n",
    "\n",
    "#sqlContext.sql(\"load data local inpath '/home/zubairidrees/hadoop-2.7.3/data/retail_db/orders' into table orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|  tableName|isTemporary|\n",
      "+-----------+-----------+\n",
      "|order_items|      false|\n",
      "|     orders|      false|\n",
      "+-----------+-----------+\n",
      "\n",
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"use retail_db_orc\")\n",
    "sqlContext.sql(\"show tables\").show()\n",
    "sqlContext.sql(\"select * from orders limit 10\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Read data from file, create dataframe & create temp table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o64.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://localhost:9000/retail_db/orders\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:60)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0a9ba983231d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from pyspark.sql import Row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morders\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/retail_db/orders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \"\"\"\n\u001b[1;32m   1279\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mtotalParts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zubairidrees/spark/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o64.partitions.\n: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://localhost:9000/retail_db/orders\n\tat org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n\tat org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n\tat org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n\tat org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\tat org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248)\n\tat org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246)\n\tat scala.Option.getOrElse(Option.scala:121)\n\tat org.apache.spark.rdd.RDD.partitions(RDD.scala:246)\n\tat org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:60)\n\tat org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql import Row\n",
    "orders =sc.textFile(\"/retail_db/orders\")\n",
    "for i in orders.take(5): print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame & temp table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(count(status)=15030, status=u'PENDING_PAYMENT')\n",
      "Row(count(status)=22899, status=u'COMPLETE')\n",
      "Row(count(status)=3798, status=u'ON_HOLD')\n",
      "Row(count(status)=729, status=u'PAYMENT_REVIEW')\n",
      "Row(count(status)=8275, status=u'PROCESSING')\n",
      "Row(count(status)=7556, status=u'CLOSED')\n",
      "Row(count(status)=1558, status=u'SUSPECTED_FRAUD')\n",
      "Row(count(status)=7610, status=u'PENDING')\n",
      "Row(count(status)=1428, status=u'CANCELED')\n",
      "1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy\n",
      "2,2,Under Armour Men's Highlight MC Football Clea,,129.99,http://images.acmesports.sports/Under+Armour+Men%27s+Highlight+MC+Football+Cleat\n",
      "3,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\n",
      "4,2,Under Armour Men's Renegade D Mid Football Cl,,89.99,http://images.acmesports.sports/Under+Armour+Men%27s+Renegade+D+Mid+Football+Cleat\n",
      "5,2,Riddell Youth Revolution Speed Custom Footbal,,199.99,http://images.acmesports.sports/Riddell+Youth+Revolution+Speed+Custom+Football+Helmet\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "ordersRDD = sc.textFile(\"retail_db/orders\")\n",
    "ordersDF = ordersRDD.map(lambda o: Row(id=int(o.split(\",\")[0] ), j=o.split(\",\")[1], price=o.split(\",\")[2], status=o.split(\",\")[3] ) ).toDF()\n",
    "#ordersDF.show()\n",
    "ordersDF.registerTempTable(\"orders_tmp\")\n",
    "ordersCountByStatus = sqlContext.sql(\"select count(status),status from orders_tmp group by status\")\n",
    "for i in ordersCountByStatus.take(30):\n",
    "    print i\n",
    "    \n",
    "productsRaw = open(\"/home/zubairidrees/hadoop-2.7.3/data/retail_db/products/part-00000\").read().splitlines()\n",
    "type(productsRaw)\n",
    "productsRDD = sc.parallelize(productsRaw)\n",
    "for i in productsRDD.take(5):print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------+\n",
      "|          order_date|order_id|   order_status|\n",
      "+--------------------+--------+---------------+\n",
      "|2013-07-25 00:00:...|       1|         CLOSED|\n",
      "|2013-07-25 00:00:...|       2|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|       3|       COMPLETE|\n",
      "|2013-07-25 00:00:...|       4|         CLOSED|\n",
      "|2013-07-25 00:00:...|       5|       COMPLETE|\n",
      "|2013-07-25 00:00:...|       6|       COMPLETE|\n",
      "|2013-07-25 00:00:...|       7|       COMPLETE|\n",
      "|2013-07-25 00:00:...|       8|     PROCESSING|\n",
      "|2013-07-25 00:00:...|       9|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|      10|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|\n",
      "|2013-07-25 00:00:...|      12|         CLOSED|\n",
      "|2013-07-25 00:00:...|      13|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|      14|     PROCESSING|\n",
      "|2013-07-25 00:00:...|      15|       COMPLETE|\n",
      "|2013-07-25 00:00:...|      16|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|      17|       COMPLETE|\n",
      "|2013-07-25 00:00:...|      18|         CLOSED|\n",
      "|2013-07-25 00:00:...|      19|PENDING_PAYMENT|\n",
      "|2013-07-25 00:00:...|      20|     PROCESSING|\n",
      "+--------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[u'1,2013-07-25 00:00:00.0,11599,CLOSED']\n",
      "[u'1,1,957,1,299.98,299.98']\n",
      "[u'1,2,Quest Q64 10 FT. x 10 FT. Slant Leg Instant U,,59.98,http://images.acmesports.sports/Quest+Q64+10+FT.+x+10+FT.+Slant+Leg+Instant+Up+Canopy']\n",
      "+--------------------+--------------------+------------------+\n",
      "|          order_date|        product_name|     daily_revenue|\n",
      "+--------------------+--------------------+------------------+\n",
      "|2013-07-25 00:00:...|Field & Stream Sp...| 5599.719999999999|\n",
      "|2013-07-25 00:00:...|Nike Men's Free 5...| 5099.489999999998|\n",
      "|2013-07-25 00:00:...|Diamondback Women...| 4499.700000000001|\n",
      "|2013-07-25 00:00:...|Perfect Fitness P...| 3359.439999999999|\n",
      "|2013-07-25 00:00:...|Pelican Sunstream...|2999.8499999999995|\n",
      "|2013-07-25 00:00:...|O'Brien Men's Neo...|2798.8800000000006|\n",
      "|2013-07-25 00:00:...|Nike Men's CJ Eli...|1949.8500000000001|\n",
      "|2013-07-25 00:00:...|Nike Men's Dri-FI...|            1650.0|\n",
      "|2013-07-25 00:00:...|Under Armour Girl...|           1079.73|\n",
      "|2013-07-25 00:00:...|Bowflex SelectTec...|            599.99|\n",
      "|2013-07-25 00:00:...|Elevation Trainin...|            319.96|\n",
      "|2013-07-25 00:00:...|Titleist Pro V1 H...|            207.96|\n",
      "|2013-07-25 00:00:...|Nike Men's Kobe I...|            199.99|\n",
      "|2013-07-25 00:00:...|Cleveland Golf Wo...|            119.99|\n",
      "|2013-07-25 00:00:...|TYR Boys' Team Di...|            119.97|\n",
      "|2013-07-25 00:00:...|Merrell Men's All...|            109.99|\n",
      "|2013-07-25 00:00:...|LIJA Women's Butt...|             108.0|\n",
      "|2013-07-25 00:00:...|Nike Women's Lege...|             100.0|\n",
      "|2013-07-25 00:00:...|Team Golf Tenness...|             99.96|\n",
      "|2013-07-25 00:00:...|Bridgestone e6 St...|             95.97|\n",
      "+--------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "orders = sc.textFile(\"retail_db/orders\")\n",
    "order_items = sc.textFile(\"retail_db/order_items\")\n",
    "products = sc.textFile(\"retail_db/products\")\n",
    "\n",
    "ordersDF = orders.map(lambda o: Row(order_id=int(o.split(\",\")[0]) , order_date=o.split(\",\")[1], \\\n",
    "                                    order_status=o.split(\",\")[3])).toDF()\n",
    "\n",
    "orderItemsDF = order_items.map(lambda oi:Row(order_item_id=int(oi.split(\",\")[0]) , order_id=int(oi.split(\",\")[1]), \\\n",
    "                                             product_id=int(oi.split(\",\")[2]), revenue=float(oi.split(\",\")[4]) ) ).toDF()\n",
    "productsDF = products.map(lambda p:Row(product_id=int(p.split(\",\")[0]) , product_name=p.split(\",\")[2])).toDF()\n",
    "\n",
    "ordersDF.show()\n",
    "\n",
    "print orders.take(1)\n",
    "print order_items.take(1)\n",
    "print products.take(1)\n",
    "\n",
    "ordersDF.registerTempTable(\"orders\")\n",
    "orderItemsDF.registerTempTable(\"order_items\")\n",
    "productsDF.registerTempTable(\"products\")\n",
    "\n",
    "sqlContext.setConf(\"spark.sql.shuffle.partitions\",2)\n",
    "sqlContext.sql(\"select o.order_date, p.product_name ,sum(oi.revenue) as daily_revenue \\\n",
    "                from orders o join order_items oi on o.order_id = oi.order_id \\\n",
    "                join products p on p.product_id = oi.product_id \\\n",
    "                where o.order_status in ('COMPLETE','CLOSED') \\\n",
    "                group by o.order_date, p.product_name \\\n",
    "                order by o.order_date ,daily_revenue  desc\").show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
